

# 程序运行原理

## 前言

> 程序可以是一行函数库的调用，可以是自己实现的函数，可以是自己实现的一个系统......

为了明白程序运行时本质的需求，需要弄明白程序运行原理，见下文。



## 正文

>正文从程序运行出发，了解操作系统的基本知识；
>
>基于并发请求的处理方式，了解程序运行的资源调度；
>
>进而扩展到性能问题，了解Web应用架构，线程相关的问题与高并发问题解决方案。
>
>阅读本文，需要具备一定的领域知识。

### 一、程序是如何运行起来的

**程序**的大致分类：

 - 文本格式的代码

 - 可执行代码（编译后）

 - 程序是静态的，存储在磁盘上

**进程**是什么？程序运行过程中的**加载过程**是什么？

   - 程序加载到内存，在操作系统的管理调度下交给CPU执行，运行起来
   - 进程包含：可执行的程序代码，运行期使用的内存堆空间（存储数据结构），栈空间（函数栈），供操作系统管理用的进程数据结构
   - 操作系统将可执行代码加载到内存，生成相应的数据结构和内存空间，从可执行代码的起始位置读取指令交给CPU顺序执行
   - 指令执行会遇到一条跳转指令
   - 程序运行时需要创建数组等数据结构，操作系统会在进程的**堆空间**申请一块相应的内存空间，并把这块内存的首地址信息记录在**进程的栈**中
   - **堆**是一块无序的内存空间，进程申请内存，都会从堆空间中分配，分配的内存地址则记录在栈中
   - **栈**是先进后出的数据结构，由操作系统维护，记录函数内部的局部变量，和堆空间分配的内存空间地址
   - 每次函数调用，操作系统都会在栈中创建一个栈帧（Stack frame），正在执行的函数参数，局部变量，申请的内存地址都在当前栈帧中，也就是堆栈的顶部栈帧中
   - 真正执行的函数永远都在栈顶，由于栈帧是隔离的，所以不同函数可以定义相同的变量而不会发生混乱

![程序加载过程](1-程序运行原理.assets/程序加载过程.png)



![函数栈压栈](1-程序运行原理.assets/函数栈压栈.png)







### 二、如何同时处理数以百计的任务

**PC计算机**简介：

- 一核心，两核心，....，多核心
- 编程，听英语，执行下载任务，....，多任务并行

**服务器**简介：

- 更多的CPU核心
- 同时处理数以百计甚至数以千计的并发用户请求

操作系统的**CPU分时共享技术**是什么？

- 当存在多个进程在执行，**操作系统将CPU的执行时间分成很多份**，进程按照某种策略，保证在CPU上运行
  每个进程似乎独占一个CPU执行，在极短的时间内切换CPU计算资源

- 在实际的物理上，进程并不总是在CPU上运行

  - 由于共享CPU，需要等待CPU运行

  - 由于进程执行I/O操作，不需要CPU执行

**进程生命周期**是什么？

- 运行
  - 处于运行状态的进程的数目小于等于CPU数目
- 就绪
  - 当进程获得除了CPU之外的所有资源，只要得到CPU即可运行，即为就绪状态，也被称为等待运行状态
- 阻塞
  - 称为等待或者睡眠状态，当一个进程等待某一个时间发生等待，如锁，I/O等，则会暂时停止运行

**线程**是什么?

- 由于每次进行进程间CPU切换，代价非常大
- 实际，**每一个用户请求对应的是一个线程**
- 线程是轻量级的进程，在线程内部创建，拥有自己的**线程栈**，在CPU上进行线程切换的代价也更小
- 线程的生命周期状态等同于进程
- 线程栈都是完全隔离的，每个方法的参数和方法内的局部变量都是隔离的，一个线程无法访问到其他线程的核内数据





### 三、系统为什么会变慢和崩溃

服务器软件系统主要使用**多线程技术实现多任务处理**，完成多用户的并发请求处理

开发的应用程序，以一个进程在操作系统中启动，在进程中创建很多线程，每一个线程处理一个用户请求

**java Web 应用**开发运行时主要架构（架构过程视图）

- 启动多线程，为每一个用户请求分配一个处理线程的工作是在Web容器中完成，如Tomcat容器
- Tomcat启动多个线程，为每一个用户请求分配一个线程，调用和请求URL路径相对应的Servlet（或者Controller）代码，完成用户请求处理
- 操作系统将硬件进行分时（CPU），分片（内存），虚拟化成一个独享资源，让JVM进程在其上运行
- Tomcat在JVM虚拟机进程中
- JVM虚拟机被操作系统当做一个独立进程管理
- 不管你是否有意识，开发的web程序是被多线程执行的，**web开发天然就是多线程开发**

![javaweb开发](1-程序运行原理.assets/javaweb开发.png)



**线程安全问题**有哪些？

- 当某些代码**修改内存堆**里的数据的时候，如果有多个线程在同时执行，就会出现同时修改数据的情况
- 多个线程访问共享资源的这段代码称为**临界区**
- **锁**
  - 解决线程安全问题的方法是使用锁，将临界区的代码加锁
  - 线程获取锁的时候，锁已经被其他线程获取，没有释放，该线程就会进入阻塞状态
- **锁如何保证自己是线程安全**
  - 在java中，锁是通过**CAS**把当前线程ID刷新到对象头的信息里
  - 在获取锁时，先去头信息里拿这个信息，如果没有，则会CAS刷新进去，刷新成功就会获得锁，刷新失败就表明别的线程也在尝试刷新这个信息
  - 在操作系统层面，有**PV操作**保证原子性，而PV操作也是利用**CPU中原语指令**，在获取锁时保证不会被别的指令打断，或被重排序
- PV操作
  - P就是请求资源，V就是释放资源。 
  - P操作是减法运算（S:=S-1），当信号量S小于0时申请资源；
  - V操作是加法运算（S:=S+1），当信号量S大于等于0时释放资源；
  - P、V操作二者必须成对出现。

**线程阻塞**的原因？

- **锁**会引起线程阻塞，多个线程同时运行，会出现线程排队等待锁的情况
- 线程**无法并行**执行的时候，系统的响应速度就会变慢
- **I/O操作**也会引起阻塞，数据库的连接阻塞
- 典型的web应用基于RDBMS关系数据库，获得数据库连接，受限制于**数据库资源**，每个web应用能建立的数据库连接数是有限的
- 使用**数据库连接池**的时候，线程数大于连接池大小，就会出现多余线程的阻塞等待
- 当多个线程无法获得数据库的连接，web请求者就会看到，系统变慢，响应时间变长

**应用崩溃**的原因？

- 被阻塞的线程越多，占用系统资源也就越多
- 阻塞的线程不能释放当前资源，也不能继续执行，在系统中一边等待一边消耗资源
- 阻塞线程数超过某个系统资源的极限，就会导致系统宕机，应用崩溃

**分布式系统架构**解决方案？

- 解决系统因高并发而导致的响应变慢
- 服务器构建一个集群
- 必要时在请求入口处进行限流，减小系统的并发请求数
- 在应用内进行业务降级，较小线程的资源消耗



## 结束语

文中涉及的知识包括：**计算机组成，操作系统，进程， 线程，内存堆，线程栈，锁，原子操作，web应用，性能问题等**。

需要记住的几点：

**1.每一个web应用，最终处理用户请求的基本单位是线程（可同步，可异步），并且天然并发（不需要自己写，容器自动完成）；**

**2.最简单保证并发数据一致性的方法，是利用每个线程栈的天然隔离性，即函数栈中的私有变量天然隔离；**

**3.应用扩展的精选方案，是分布式系统架构，属于治本方案。**








