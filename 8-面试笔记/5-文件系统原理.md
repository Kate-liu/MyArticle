

# 文件系统原理

## 前言

>关于文件系统，大家都不会陌生，只是基于文件系统深入探讨数据存储的方式，这就比较难了。
>
>Windows系统上的文件资源管理器，就是一个文件系统，以此作为认识整个文件系统的开始吧！

## 正文

>正文，会从最基本的硬件资源（硬盘）出发，认识数据的存储过程；升维看文件系统这个软件是怎么组织数据的；将其扩展为服务器的RAID，看看数据的可靠性保证；探讨分布式文件系统中应用，以Hadoop为例，看一下HDFS。
>

### 一、硬盘

- 硬盘是一种可以持久保存，多次读写数据的存储介质
- **机械硬盘**
  - 包含盘片，主轴，磁头臂
  - 主轴带动盘片高速旋转，当需要读写盘上的数据时，磁头臂会移动磁头到盘片所在的磁道上，读取数据
  - 由于读写数据，需要移动磁头，这是一个机械动作，至少需要花费数毫秒的时间，这是机械硬盘访问延迟的主要原因
  - 如果文件存储在硬盘上不是连续存储，如数据库的B+树文件，读取文件，磁头臂就需要来回移动，花费时间更长
  - 如果数据存储在硬盘上是连续存储，如日志文件，磁头臂的移动较少，读写文件的速度快很多
  - 机械硬盘的数据，存储在具有磁性特质的盘片上，这种硬盘也被称为磁盘
- **固态硬盘**
  - 固态硬盘，包含主控芯片，处理端口输入的指令和数据，然后控制闪存颗粒进行数据读写
  - 固态硬盘，没有机械操作，完全的电子操作，导致访问速度远快于机械硬盘
  - 固态硬盘的成本明显高于机械硬盘
  - 生产环境中，主要使用的还是机械师硬盘
  - 如果对数据访问速度，存储容量，成本的要求较高，可以使用机械与固态硬盘的混合部署
  - 将日志文件存储在机械硬盘，文件系统和随机读写的文件存储在固态硬盘



### 二、文件系统

- 文件系统是一个软件
- 不直接操作硬盘，通过操作系统，以文件的方式对硬盘上的数据进行读写访问
- 文件系统将硬盘空间以**块**为单位进行划分，每个文件占据若干个块，通过一个文件控制块FCBj记录每一个文件占据的硬盘数据块
- **文件控制块在Linux操作系统中，是inode**
- 想访问文件，需要获得文件的inode信息，在inode中查找数据块索引表，根据索引记录的硬盘地址信息访问硬盘，读写数据
- **inode记录着文件权限，所有者，修改时间，文件大小等文件属性信息**
  - inode是固定结构的，只有15个索引
  - 前12个索引直接记录数据块地址
  - 第13个索引记录索引地址，即索引块指向的硬盘数据并不直接记录文件数据，而是记录文件数据块的索引表，每个索引表可以记录256个索引
  - 第14个索引，记录二级索引地址
  - 第15个索引记录三级索引地址
  - 这样，一个inode最多存储12+256x256+256x256x256个数据块
  - 如果每一个数据块的大小为4K，也就是单个文件最大不超过70G
  - 即时扩大数据块的大小，文件大小也要受限制单个硬盘的容量控制

![文件系统](5-文件系统原理.assets/文件系统.png)

![inode文件块](5-文件系统原理.assets/inode文件块.png)





### 三、RAID

- RAID，即独立硬盘冗余阵列，将多块硬盘通过RAID卡，或者软件RAID的方案管理起来，使其共同对外提供服务
- RAID的核心思路，利用文件系统将数据写入硬盘中不同数据块的特性，将多块硬盘上的空间看做一个整体，进行数据写入
- 一个文件的多个数据块可能写入多个硬盘
- RAID，根据硬盘组织和使用方式分为五种
- **RAID 0**
  - 将文件的数据分成N片，同时向N个硬盘写入
  - 这样单个文件可以存储在N个硬盘上，文件容量扩大N倍，理论上读写速度扩大N倍
  - 由于文件数据分散N块硬盘，任何一块损坏，整个数据就不完整，文件可用性太低
- **RAID 1**
  - 利用两块硬盘进行数据备份，同时向两块硬盘写入
  - 任何一块硬盘损坏，都不会出现文件数据对视，提高可用性
- **RAID 10**
  - 结合RAID0和RAID1，将多块硬盘进行两两分组，文件数据分成N片，每个分组写入一片，每个分组内的两块硬盘进行数据备份
  - 扩大了文件容量，提高了文件可用性
  - 由于冗余备份，硬盘利用率太低，为50%
- **RAID 5**
  - 改进RAID 10方案，保证不浪费，将数据分为N-1片，利用这个N-1片数据进行位运算，计算一片校验数据，然后将这N片数据写入N个磁盘
  - 这样磁盘的损坏，都可以利用校验片的数据，和其他数据进行计算，得到这片丢失的数据
  - 磁盘的利用率为 N-1 / N
  - 如果两块磁盘坏了，就会出现数据丢失
  - **RAID 5的校验位数据，不是单独存储在一块硬盘上，而是分散在不同的盘上，实际上检验数据的存储位置是螺旋式的落在所有硬盘上**
  - RAID 5的校验位之所以螺旋式落在所有磁盘上，主要原因是如果将校验位记录在同一块硬盘上，那么对于其他多块数据盘，任何一块硬盘修改数据，都需要修改这个校验盘上的数据
  - 对于有8块硬盘的RAID 5阵列，校验盘的数据写入压力是其他数据盘的7倍，而硬盘的频繁写入会导致硬盘的寿命缩短，校验盘会频繁损坏，存储的整体可用性和维护性都会变差
  - 不仅仅考虑软件本身，还需要了解的软件的各种约束，硬盘的也行约束是一种
- **RAID 6**
  - 解决两块硬盘损坏问题
  - 使用两种问运算校验算法，计算两片校验数据
  - 当两块磁盘损坏，可以通过两片校验数据计算得到对视数据
  - 实际中，常用方案是RAID5
  - 一台服务器上能插入的硬盘数量有限，是8块
  - 即文件读写速度和存储容量都扩大了7倍

![RAID](5-文件系统原理.assets/RAID.PNG)





### 四、分布式文件系统

- 基于Linux的文件系统思路，**将数据块的地址改为分布式服务器的地址**，那么文件的存储容量将是整个分布式服务集群的硬盘容量
- 还可以在不同服务器上同时并行读取文件的数据块，文件访问速度也会加快
- 分布式文件系统思路和RAID是一脉相传。就是将数据分成很多片，同时向N台服务器上进行数据写入
- 针对一片数据丢失导致整个文件损坏的问题，分布式文件系统采用数据备份的方式，将多个备份数据片写入多个服务器，保证文件的可用性
- 也可以采用RAID 5的方式，计算校验数据片的方式提高文件可用性



### 五、例子：Hadoop分布式文件系统HDFS

- **DataNode：负责文件数据的存储和读写操作**
  - HDFS将文件数据分割成若干数据块（Block），每个DataNode存储一部分数据块
  - 此时，文件就分布存储在整个HDFS服务器集群中
  - 客户端（Client），可以通过并行对数据块访问，使得HDFS在服务器集群规模上实现数据并行访问，提高访问速度
  - 实践中，DataNode服务器会与很多台，几百到几千台规模，每台配置数块硬盘，整个集群存储容量在几PB到数百PB
- **NameNode：负责整个分布式文件系统的元数据（MetaData）管理**
  - 保存文件路径名，访问权限，数据块ID，存储位置等信息
  - 保证数据高可用
  - HDFS会将数据块复制为多份（缺省为3份），并将多份相同的数据块存储在不同的服务器上，甚至不同机架上
  - 当硬盘损坏，DataNode服务器宕机，某个交换机宕机等情况，都会有备份数据使用
- HDFS可以实现几百T的数据存储，配合大数据计算框架MaoReduce或者Spark。可以对文件的数据块进行并发计算
- 使用Impala这样的SQL引擎对文件进行结构化查询，在数千台服务器遍历100T数据，不需要1分钟

![hdfs](5-文件系统原理.assets/hdfs.png)





## 结束语

文中涉及的知识包括：**机械硬盘，固态硬盘，文件系统，RAID，分布式文件系统，HDFS，文件控制块，inode，DataNode，NameNode。**

需要记住的几点：

**1.在使用硬盘存储数据的时候，想要保证高性能，唯一的办法就是顺序写入。**

而保证顺序写入的思路是：添加一个缓存层，将所有需要写入的数据进行缓存，到达一定量后写入硬盘，这也是分布式键值存储数据库Cassandra的写操作方案。

**2.RAID的使用，本质是增加数据校验，扩展数据的可用性。即，在不增加太多成本的情况下，获得较高的可用性。**

**3.文件系统，本质都是需要两部分：一部分存储数据，另一部分存储数据块的位置和数据的属性等。**




